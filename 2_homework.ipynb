{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "from razdel import tokenize\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: \"\\l\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\l\"? A raw string is also an option.\n",
      "<>:1: SyntaxWarning: \"\\l\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\l\"? A raw string is also an option.\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_15148\\120440491.py:1: SyntaxWarning: \"\\l\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\l\"? A raw string is also an option.\n",
      "  data = pd.read_csv(\"O:\\ВШЭ Магистратура\\НИС Актуальные проблемы компьютерной лингвистики\\Домашние работы\\labeled.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"O:\\ВШЭ Магистратура\\НИС Актуальные проблемы компьютерной лингвистики\\Домашние работы\\labeled.csv\")\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4f29d",
   "metadata": {},
   "source": [
    "**Дефолтный токенизатор**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbffbbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12970, 63980)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff0449a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1442, 63980)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vectorizer.transform(test.comment)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55893474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.61      0.69       949\n",
      "         1.0       0.49      0.71      0.58       493\n",
      "\n",
      "    accuracy                           0.64      1442\n",
      "   macro avg       0.64      0.66      0.64      1442\n",
      "weighted avg       0.69      0.64      0.65      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "default_preds = clf.predict(X_test)\n",
    "default_f1 = f1_score(y_test, default_preds, average='weighted')\n",
    "\n",
    "print(classification_report(y_test, default_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b645e21e",
   "metadata": {},
   "source": [
    "**razdel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6ffa1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12970, 64923)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def razdel_tokenizer(data):\n",
    "    return [token.text for token in tokenize(data)]\n",
    "vectorizer = CountVectorizer(tokenizer=razdel_tokenizer)\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d2477b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1442, 64923)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vectorizer.transform(test.comment)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "808e4178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.76      0.78       949\n",
      "         1.0       0.58      0.63      0.60       493\n",
      "\n",
      "    accuracy                           0.72      1442\n",
      "   macro avg       0.69      0.69      0.69      1442\n",
      "weighted avg       0.72      0.72      0.72      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "razdel_preds = clf.predict(X_test)\n",
    "razdel_f1 = f1_score(y_test, razdel_preds, average='weighted')\n",
    "\n",
    "print(classification_report(y_test, razdel_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "baaeb90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Победил: razdel\n"
     ]
    }
   ],
   "source": [
    "if default_f1 > razdel_f1:\n",
    "    winner = \"sklearn\"\n",
    "elif razdel_f1 > default_f1:\n",
    "    winner = \"razdel\"\n",
    "else:\n",
    "    winner = \"Draw\"\n",
    "    \n",
    "print(f\"Победил: {winner}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd827094",
   "metadata": {},
   "source": [
    "**CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f53ffbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.93      0.91       949\n",
      "         1.0       0.85      0.77      0.81       493\n",
      "\n",
      "    accuracy                           0.87      1442\n",
      "   macro avg       0.87      0.85      0.86      1442\n",
      "weighted avg       0.87      0.87      0.87      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True, min_df=3, max_df=0.85, ngram_range=(1, 2), strip_accents='unicode', max_features=10000)\n",
    "X1 = vectorizer.fit_transform(train.comment)\n",
    "X1_test = vectorizer.transform(test.comment)\n",
    "\n",
    "clf1 = MultinomialNB(alpha=0.5, fit_prior=True, force_alpha=True)\n",
    "clf1.fit(X1, y)\n",
    "preds1 = clf1.predict(X1_test)\n",
    "CV_f1 = f1_score(y_test, preds1, average='weighted')\n",
    "\n",
    "print(classification_report(y_test, preds1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e54936",
   "metadata": {},
   "source": [
    "**TfidfVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.73      0.77       949\n",
      "         1.0       0.56      0.67      0.61       493\n",
      "\n",
      "    accuracy                           0.71      1442\n",
      "   macro avg       0.69      0.70      0.69      1442\n",
      "weighted avg       0.72      0.71      0.71      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, min_df=2, max_df=0.9, ngram_range=(2, 3), strip_accents='unicode')\n",
    "X2 = vectorizer.fit_transform(train.comment)\n",
    "X2_test = vectorizer.transform(test.comment)\n",
    "\n",
    "clf2 = LogisticRegression(C=1.0, class_weight='balanced', max_iter=1000)\n",
    "clf2.fit(X, y)\n",
    "preds2 = clf2.predict(X_test)\n",
    "TF_f1 = f1_score(y_test, preds2, average='weighted')\n",
    "\n",
    "print(classification_report(y_test, preds2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c8b25a",
   "metadata": {},
   "source": [
    "**10 самых токсичных текстов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d134a833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [True: 1.0, Prob: 1.0000] Поясняю за Била. Те, кто его смотрит отморозки, или быдло. Они просто не могут представить, что могут оказаться в такой ситуации. А для них омежки это скот, но когда затрагивают их ЧСВ совершенно безобидным пранком, когда облили водой раздвиженцев, то быдло и отморозки встают в позу и говорят о НАРУШЕНИЕ ГРАНИЦ. Тем, кому припекает омежки, которые из-за низкой самооценки неосознанно представляют себя на месте героев пранка. А потом в своих влажных фантазия избивают этого пранкера или пытают его. А нормальные люди просто это не смотрят. А если и посмотрят то просто скажут, что он дурак. Бил же трус и быдло -- доебывается обычно до слабых, что свойственно гопоте. Очень удивилась, что у него так много лайков на видосах. Ну видимо это те, кто любят Хованского, Мопса и прочих быдлоютуберов. Не удивлюсь, что Била смотрят в основном не из приличных городов, а из всяких мухасрансков. Вывод, русские терпилы будут терпеть до конца. Как лев против или стопхам(который уже окуклился). Включу либераста, как видите это типичный руSSкий мир, мы готовы превозносить любое быдло в герои, а потом оправдывать его. С Билом ниче не случится, я гарантирую это. Он явно не тупой и точно знает, где граница дозволенного, то есть мы не увидим его с ЛГБТ-флагом в Чечне, например. Так что, дорогие руSSкие сосите и дальше хуй и терпите. Мимо проходила\n",
      "...\n",
      "2. [True: 0.0, Prob: 1.0000] Нет, пожалуй, отвечу развернутее. Представь, что тебя ограбили. Ты идешь в частную полицию, выкладываешь бабки на стол, говоришь о случившемся. Полицаи по мере своих сил расследуют инцидент. Они дают тебе список потенциальных преступников, вероятнее всего, из одного человека. Ты приходишь к человеку, говоришь, так и так, чувак, я тебя подозреваю, хочу судиться. Если он тоже хочет судиться, то он идет с тобой в выбранный вами обоими суд. Если не хочет, то ты обращаешься в суд со своей доказательной базой, он приходит к человеку и обращается с подобной фразой: вы, гражданин такой-то такой-то, обвиняетесь по тому-то тому-то. Пройдите с нами в зал суда для разбирательств, или мы, согласно статье такой-то такой-то действующего законодательства имеем право вас наказать. Если человек соглашается, то вы судитесь. Если он виновен, то ему назначается наказание и он оплачивает издержки суда, если нет, то ты оплачиваешь издержки суда и идешь искать преступника дальше силами частной полиции. Звучит пиздец как плохо, да? Ну так вот, РЫНОЧЕК ПОРЕШАЕТ так, чтобы все работало куда эффективнее. Вместо хождения по частным полицейским бюро ты, скорее всего, возьмешь у одного или нескольких из них страховку на случай примененных в твою сторону правонарушений. Для них профит в том, что они будут стабильно получать от тебя бабки, для тебя - в том, что ты можешь спать спокойно. Сами частные полицаи уже заключают контракты с судами, чтобы избежать анальной ебли с твоим хождением туда-сюда, взамен они сами ходят по предполагаемым преступникам и предлагают им пройти судиться. На самом рынке останутся наиболее эффективные суды и полицаи, потому что неэффективным никто не захочет заносить бабки. Остается вопрос: в чем тебе профит ходить в суд, если ты в жизни и мухи не обидел, кроме избежания наказания, которого ты и не заслуживаешь? И даже это порешает рыночек, потому что, очевидно, суды, которые компенсируют или даже поощряют тебя за то, чтобы ты к ним ходил, даже если ты невиновен, будут выглядеть более привлекательно. Надеюсь, на вопрос я ответил. К слову, продажные суды не будут популярны как раз из-за своей продажности, потому что выгоду от этого получает только искодатель, и то только тогда, когда дает иск ни за что. А государство из судов не вырастет как раз потому, что сами суды не будут обладать оружием, им будут обладать полицаи. Ну и конкуренция, опять же. Апелляции подавать в высшие суды, которые будут работать по тем же принципам.\n",
      "...\n",
      "3. [True: 1.0, Prob: 1.0000] Ебать, кто смотрит сыромятникова?? Где еще можно найти настолько отталкивающий тембр голоса и манеру говорить?? Блять а полезный контент в стиле - сейчас я покажу как играть на гитаре с автотюном - который уже давно был у западников? А его охуенные видео как сделать песдатый звук, где звук выхожит полным мутным говном, потому что он напрямую в дешевую звуковую карту играет? А его бородка ебаная?? Что это блять? А блять когда он палится с подложенной аудиодорожкой когда играет на камеру, причём блять настолько нелепо, что даже видео заметно замедляет, чтобы попадало в звук, а потом говорит, что так оно все и задумано? А его блять гиперкривляния и гримасы во время игры?? Что это за пиздец? Видно же, что специально старается показать ДУШУ , которой у него на самом деле нет!! Блять у меня такой испанский стыд со всей этой хуйни ебаный в рот! Теперь еще у него будет ебанутая истеричка-жена, которая его уже загнала под неебический каблук, и будет его уничтожать окончательно. Бляя она тоже хороша. Поет мягко говоря, МЯГКО ГОВОРЯ не всегда хорошо(об этом еще Зилков мягко намекал, в его способностях никто не сомневается), зато при любом удобном случае говорит о том, что у нее неебичское ололо образование, охуенный опыт в педагогический, в ответ на сомнения в ее способностях певческих она сделала попытку страйка по авторским правам, ЗАСТАВИВ ЕЩЕ ДВУХ МУЖИКОВ ТОЖЕ ЕЕ СДЕЛАТЬ , а когда закономерно соснула, устроила истерический стрим, где стуча руками по столу на полном серьезе человека сравнивала с БАНЫМ ГИТЛЕРОМ БЛЯТЬ , который миллионами уничтожал людей ирл, а не в ютубе, затем приправив все охуительной порцией слез и соплей под омежные кукареки своего муженька? Блять это что за фантасмагория нахуй? Is this the real life?\n",
      "...\n",
      "4. [True: 1.0, Prob: 1.0000] Да Евген просто шлюшка без мнения - то блядь пиндосы ему плохие КОКОКО НА КРОВИ ВТОРОЙ МИРОВОЙ ПОДНЯЛИСЬ (намекая на поставки оружия совкам за бабки, только если бы не муриканское вооружение - сосали бы мы все сейчас длинный болт товарища фюрера) То блядь совки ему плохие - сплошная гебня и гулаги, то сука СОВКИ ХОРОШИЕ КОКОКО - НЕПРАВДА НЕ ВСЯ СТРАНА ГУЛАГ. СУКА АЖ ТРЯСЕТ. А споледний обзор - это вообще КРУЖКА - ЛУКЪЯНЕНКО КОКОКО ВЕЛИЧАЙШИЙ ФАНТАСТ СОВРЕМЕННОСТИ Я ЕЩЕ В 2005 НА НЕГО ДРОЧИЛ ПОКА ЭТО НЕ БЫЛО МЭЙНСТРИМОМ КАК ВАМ НЕ СТЫДНО ЗЛОСТНЫЕ КИНОДЕЛЫ ОБСИРАТЬ И ПОГАНИТЬ ТВОРЧЕСТВО ЭТОГО ВЕЛИКОГО ЧЕЛОВЕКА О ЛУКЪЯНЕНКО КОКОКО КОКОКО ДАЙТЕ Я ЕМУ ОТСОСУ и сука тутже через 15 минут АЙ АЙ АЙ АВТОР САМ ОДОБРИЛ ВСЕ ОТКЛОНЕНИЯ ОТ СУЖЕТА КНИГИ КАК НИХОРОШО АЙ АЙ АЙ - но даже тут побоялся сказать прямо - Лукъяненко продался - нет он увиливает и юлит как змея, ак червь, как червь ПИДОР. БЭДКОМЕДИАН - хуже червя ПИДОРА\n",
      "...\n",
      "5. [True: 1.0, Prob: 1.0000] Целью встречи стали переговоры о сохранении поставок газа А что, у него есть полномочия вести такие переговоры? Сука блядский цирк. Какие же хохлы дегенераты, пиздец просто\n",
      "...\n",
      "6. [True: 1.0, Prob: 1.0000] дерейлы тредов за счёт постоянных провокаций, неуместных форсов, чатиков и оскорблений других анонов в нём также приведут к бану. 7 постов гомофорса на 100, вот уж проблема и засирание треда Гомофорс - это, прежде всего, форс. Он прикрывается традицией и местными обычаями, а его апологеты утверждают, что форс смешной и без него уже нельзя. Никто не называет его смешным, никто не говорит, что без него нельзя. Всех в конец заебало обсуждение одних тем и анон так развлекается. Последние свитки вышли в 11м, тесо и легенды никто не играл, а некоторые особо одарённые и вовсе считают никаноном. А гомофорс это просто общение в треде обо всём без чёткой тематики. Однако если это форсится без меры 3 года подряд и просачивается в другие треды, раздражая анонов, то это должно пресекаться. просачивается в другие треды Вот и бань тех кто просачивается без меры Где ты был полтора года назад, когда на доске висело 35 вопросов тредов? Вот это было без меры, но теперь даже гринтекстовых срачей почти нет. Теперь приходится вставлять гомофорс в обычные посты, но даже их трут: А это и вовсе ответ на вопрос о гомофорсере, который был ни с хуя потёрт 1257469 Он тут не пролазит, это его доска. Гомофорс - неотъемлемая часть тесача, существующая уже два с половиной года. А вот как сюда пролазят гомохейтерки вроде тебя - это вопрос. Системность следования правилам раздела, отсутствие избирательного отношения или фаворитизма по отношению к тому или иному форсу, - Ага, поэтому меня забанили за гомофорс вчера, а не за данмерских шлюх неделю назад. залог стабильного постинга на честной доске. Будто бы гомофорс мешает общению. Опять же, 35 тредов полных гринтекста и простыней шизиков. И никто никому не мешал. Причина по которой на него раньше закрывали глаза это были местные юморески. Один из предыдущих мочеров назвал это традицией. Не помню ни одного случая, когда банили за посты, приведённые выше, всегда за гринтекст. Но гринтекст прекратился - начались баны за любое упоминание гомофорса. Поэтому аноны, упорствующие в гомофорсе, могут и будут забанены на средние сроки - неделю или две. Особо упорствующие могут попасть под пермач. Вот и всё. Вот только с хуя ли моча мешает общению анонов. Ни один из недавних постов с гомофорсом не получил продолжения в виде однострочного срача, с хуя ли их потёрли? Чем плох этот пост? Нет 100 правдивой версии замерзания Атморы, а хедканон у каждого свой, как завещал мишаня. Мой хедканон делает моче ниприятно? Когда норды сидели под сапогом альдмеров великой Альтморы всё было нормально. В Сиродиле джунгли, на Альтморе тёплый климат, а весь Скайрим был покрыт лесами. Всё дело в том, что альдмеры проводя ритуалы, славящие их богов, создавали много тепла своими жаркими телами, мужчины альдмеры трудились не покладая удов, чтобы поддерживать благоприятный климат, но норды были холодны и безнравственны. Мужчинам они предпочитали женщин, а такая порочная, грязная любовь не сравнится с жаром пылких альдмерских мужчин, сплетаясь образующих столько тепла, что хватает на весь континент. Когда пришла власть нордов и Обманщика, все альдмеры были убиты, а великие традиции мужской любви попали под запрет, и некогда вечнозелёная Альтмора начала превращаться в ледяную пустошь Атмору. В итоге норды сами были вынуждены бежать в Скайрим, где они вырезали фалмеров, из-за чего половина Скайрима сейчас непригодна для жизни из-за холода. Та же участь постигла и айлейдов, и вместо влажных джунглей в Сиродиле теперь простые леса. Раньше гринтекстовый срач был развёрнутый, с подробным описанием того, кто кому куда и в каком количестве суёт. И это не банилось. Может моче просто нравились эти гомоэротические рассказы, и он на нас сердится, из-за того что они перестали быть оригинальными, а потом от них и вовсе отказались. Ты скажи нам, думаю это можно исправить....\n",
      "7. [True: 1.0, Prob: 1.0000] Хохлятский, или как там его, либеральный дебил-куколд, фемка-наоборот, верещащий про угнетение и вирджин-шейминг. Таков любой мисп, его ебут, а он крепчает. Иоганн годный, но все больше скатывается в мракобесие на почве ненависти к детям (обычно в МД принято ненавидеть баб, но их он как раз жалует, а дети у него недавно массово вырезали кошек в Москве во славу сатаны). Часто с умным видом и безаппеляционной интонацией несет полнейшую хуету. У Нестерова слишком уж хуевое качество. Не осиливаю 90 его высеров: косноязычно, мыльно. Недавнее создание нового МД вызвано горящей жопой от хейтеров, типа создам движуху, а вас туда не возьму. Новоселов скучный и поехал на ватной теме. Ищет английскую королеву под кроватью. Получается, кроме Иоганна смотреть и некого. Угораю с того, как у аметистов горит жопа в комментах, когда он поповские темы задвигает.\n",
      "...\n",
      "8. [True: 1.0, Prob: 1.0000] Ну давай разберём всё тобой написанное. Бляядь, вы действительно думаете вы лучше пидорашек? Ну в целом, всё что живёт в рашке - затронуто говномидасом, но никто тут это не признает. сейчас воспитывают массу хороших кодеров В соседнем треде обоссали уже. Иди обтекай. Вы унижаете русских детей в школе Я учился в рашке и у нас был класс, который состоял онли из русачков. Думаешь, что то изменилось? Чурки тебе говна в жопу залили и заставили русачков в классе кошмарить омежных русачков? Я не люблю выражаться фразами нациков, но вы воистину столетия просто сидели в горах и ебали баранов, вас даже народ-пидор смог захватить. Плоховато ты знаешь историю. Когда русня пришла на Кавказ, тут всё уже было поделено османами и персами. А потом РИ наебала персов и постоянно нападала на османов высасывая причины из пальца, в принципе, русачки, что от них ещё было ожидать. В прошлом вы (чеченцы, даги и прочие сорта) были просто дикарями...А если говорить о среднеазиатах, которые бугуртят с оккупации, то вы были обычными нищими кочевниками Очередной акт незнания истории. Например у кавказцев по факту у народов отвественных за этногенез дагов и азеров уже был Дербент, а русачков даже в планах не было. Почитай историю Кавказа и Средней Азии, там были и локальные империи и нагибы округи и прочее и прочее. Называют русских пидорашками, славщитом. Говоришь это так, будто бы в этом что то плохое. У меня знакомые po рашеры irl, которые являются русскими и которые ссут на русню с ещё большей колокольни чем я Сейчас вас все боятся потому, что если пидорашка сделает в вас пару дырок, защищая себя, то его посадят на бутылку, а если вы убьёте пидорашку, то вам нихуя не будет. Может потому что в рашке мочить с волыны ножа человека, который идёт на тебя с кулаками - превышение пределов самообороны? Кто виноват в том, что русня настолько вырожденческая, что один чеченский доходяга ставит на колени группу русачков? Ты думаешь, будь руснявая гопота менее вырожденческая, то так же людей не кошмарила? Кто виноват, что вы морозитесь или даёте по съебатору, когда видите, как вашего славянского друга избивают унижают? Да чего уж там, тот митинг вспомните, где жирик, какого то парня на колени поставил и все вокруг стоят и снимают, словно стадо руснявых баранов. Зуб даю, в той толпе стояли его друзья и знакомые. Лично для меня это пиздец, особенно проигрываю, когда там не какой нибудь братуха-борцуха, а смарчёк чеченский. Никогда бы не бросил и не бросал друга в таком пиздеце и не важно, какой нации был друг, а какой нападавший. Вся ваша проблема не том, что вы слабками, не в том, что большинство русачков еблом похож на свинью, не в том, что за тысячу лет существования не смогли построить нормальную цивилизацию и другим не давали. Проблема в обыкновенной ошибке выжившего, вы видите кавказское быдло гопника, потому что оно в среднем сильнее, напористее, агрессивнее и образ кавказца, как лица которое представляет опасность выжигается у вас в мозгах, при этом не хотите замечать, что у вас, целые города набитые руснявыми АУЕшниками, потому что один среднестатистический руснявый гопник ауешник быдлойд сосёт у одного среднестатистического чуркобесского гопника быдлойда. В конечном итоге русачков в станице кущевской ебал кто? Другие русачки. В школу приезжали и выберали лолей на поёбку кто? Другие русачки. Сжигал русачков кто? Другие русачки. Всё вскрылось совершенно случайно. Сколько таких станиц, деревень и городов по всей рашке? аз-кун\n",
      "...\n",
      "9. [True: 1.0, Prob: 1.0000] мам, подсос! Сука какие же дауны на доске со мной сидят. Ты уже должен понять, что вся эта ваша пиздецома заебала нормальных людей, пошутили и хватит, тесач-обсуждение тес, для всего остального есть б или в худем случае ga. Я ваше мерзкое говно устал скрывать, лови сагу гнида.\n",
      "...\n",
      "10. [True: 1.0, Prob: 1.0000] Едут два пидора в трамвае. Час пик, давка. Один другому говорит: - Котик, давай ты меня выебешь прямо здесь? - Что ты, мой сладкий, тут же народу так много. - Ой, ты зря переживаешь, тут всем наплевать, никто и не заметит. - Ну не знаю... - Вот смотри. (громко) Граждане, который час? Никто даже не оборачивается. - Теперь понимаешь? Давай, снимай штаны скорее. Конечная остановка, в трамвае в одиночестве сидит пожилой мужчина. Кондуктор подходит к нему: - Дедушка, а чего вы сидите? - Ой, милок, так сердце прихватило что-то, еле дышу. - Ну так попросили бы у пассажиров валидола, у кого-нибудь да оказался бы. - Да попросишь тут, один спросил, который час, так его всю оставшуюся дорогу в жопу ебали.\n",
      "...\n",
      "1. [True: 1.0, Prob: 0.9373] Ты там помоев штоле обожрался? Или с детства имбецил? Что ты несешь?\n",
      "...\n",
      "2. [True: 0.0, Prob: 0.9244] Настенька, как здорово, что ты написала. Я ждала, я написала коммент, но ты не отвечала. Я действительно запереживала. Было грустно заходить на пикабу. А потом я увидела плюсик у коммента и поняла, что ты боец и просто сейчас не самое лучшее время для написания постов. Обнимаю\n",
      "...\n",
      "3. [True: 1.0, Prob: 0.9148] А разве Хлёбыч скрывал, что он - шлюха?\n",
      "...\n",
      "4. [True: 1.0, Prob: 0.9061] Таких как ты психопатов на хуй отстреливать в детстве.\n",
      "...\n",
      "5. [True: 1.0, Prob: 0.8880] Какие же пиндосы дегенераты, пиздец просто.\n",
      "...\n",
      "6. [True: 1.0, Prob: 0.8880] на металлолом. ни себе ни людям . какие же казахи дегенераты - пиздец просто\n",
      "...\n",
      "7. [True: 1.0, Prob: 0.8782] Поддвачну. Всем похуй на пуки маспожоров.\n",
      "...\n",
      "8. [True: 1.0, Prob: 0.8767] Какие же мерзотные зажравшиеся рожи. Прямо натуральные сеньоры помидоры из Чиполлино\n",
      "...\n",
      "9. [True: 1.0, Prob: 0.8730] Лови, сука, и знай, что у каждого украинца в сердце подобное. И если ты, мразь, попрешь сюда силой, то знвй, что ждут тебя боль и унижения\n",
      "...\n",
      "10. [True: 1.0, Prob: 0.8653] Мне одному похуй на тупое мракобесное казачьё?\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "probs1 = clf1.predict_proba(X1_test)[:, 1]\n",
    "probs2 = clf2.predict_proba(X2_test)[:, 1]\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "     'text': list(test.comment),\n",
    "     'y_true': list(y_test),\n",
    "     'CV_pred': preds1,\n",
    "     'CV_prob': probs1,\n",
    "     'TF_pred': preds2, \n",
    "     'TF_prob': probs2\n",
    "})\n",
    "\n",
    "CV_toxic_top10 = results_df.nlargest(10, 'CV_prob')[['text', 'CV_prob', 'y_true']]\n",
    "for i, (idx, row) in enumerate(CV_toxic_top10.iterrows(), 1):\n",
    "    print(f\"{i}. [True: {row['y_true']}, Prob: {row['CV_prob']:.4f}] {row['text']}...\")\n",
    "\n",
    "TF_toxic_top10 = results_df.nlargest(10, 'TF_prob')[['text', 'TF_prob', 'y_true']]\n",
    "for i, (idx, row) in enumerate(TF_toxic_top10.iterrows(), 1):\n",
    "    print(f\"{i}. [True: {row['y_true']}, Prob: {row['TF_prob']:.4f}] {row['text']}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05534a39",
   "metadata": {},
   "source": [
    "Отобрались разные тексты, но и там, и там они токсичные. Второй классификатор ошибся в предложении 2. Первый справился прекрасно!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "81f86878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['другои', 'еи', 'какои', 'мои', 'неи', 'сеичас', 'такои', 'этои'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "russian_stopwords = stopwords.words('russian')\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    lowercase=True,\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    ngram_range=(1, 2),\n",
    "    strip_accents='unicode',\n",
    "    max_features=5000,\n",
    "    stop_words=russian_stopwords  # Используем русские стоп-слова\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "def get_top_features(clf, feature_names, n=10):\n",
    "    \n",
    "    if hasattr(clf, 'coef_'):  # Logistic Regression\n",
    "        importance = clf.coef_[0]\n",
    "    elif hasattr(clf, 'feature_importances_'):  # Tree-based\n",
    "        importance = clf.feature_importances_\n",
    "    elif hasattr(clf, 'feature_log_prob_'):  # NB\n",
    "        toxic_probs = np.exp(clf.feature_log_prob_[1])  # 1 - токсичный\n",
    "        non_toxic_probs = np.exp(clf.feature_log_prob_[0])  # 0 - нетоксичный\n",
    "        importance = toxic_probs / non_toxic_probs  # отношение вероятностей\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "\n",
    "    top_features = []\n",
    "    for i in range(min(n, len(indices))):\n",
    "        idx = indices[i]\n",
    "        feature_name = feature_names[idx]\n",
    "        feature_importance = importance[idx]\n",
    "        top_features.append((feature_name, feature_importance))\n",
    "\n",
    "    return top_features\n",
    "\n",
    "models = {}\n",
    "top_features_all = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c9eee52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8183289884549476"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(\n",
    "    C=0.8,\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "lr_model.fit(X, y)\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "lr_f1 = f1_score(y_test, lr_preds, average='weighted')\n",
    "\n",
    "models['LogisticRegression'] = lr_model\n",
    "lr_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ae9997dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7236259663613449"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=800,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=4,\n",
    "    class_weight='balanced',\n",
    ")\n",
    "\n",
    "dt_model.fit(X, y)\n",
    "dt_preds = dt_model.predict(X_test)\n",
    "dt_f1 = f1_score(y_test, dt_preds, average='weighted')\n",
    "\n",
    "models['DecisionTree'] = dt_model\n",
    "dt_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "608caaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8482547090626886"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB(\n",
    "    alpha=0.7,\n",
    "    fit_prior=True\n",
    ")\n",
    "\n",
    "nb_model.fit(X, y)\n",
    "nb_preds = nb_model.predict(X_test)\n",
    "nb_f1 = f1_score(y_test, nb_preds, average='weighted')\n",
    "\n",
    "models['MultinomialNB'] = nb_model\n",
    "nb_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "15af4e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7895957041763683"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=500,\n",
    "    min_samples_split=30,\n",
    "    min_samples_leaf=3,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X, y)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "rf_f1 = f1_score(y_test, rf_preds, average='weighted')\n",
    "\n",
    "models['RandomForest'] = rf_model\n",
    "rf_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "160230bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. хохлов: 2.9219\n",
      "  2. дебил: 2.8375\n",
      "  3. хохлы: 2.7111\n",
      "  4. тупые: 2.2623\n",
      "  5. дебилов: 2.1911\n",
      "  1. хохлы: 0.0240\n",
      "  2. тебе: 0.0233\n",
      "  3. очень: 0.0228\n",
      "  4. хохлов: 0.0202\n",
      "  5. нахуи: 0.0185\n",
      "  1. очень: 0.0169\n",
      "  2. хохлы: 0.0145\n",
      "  3. хохлов: 0.0132\n",
      "  4. тебе: 0.0131\n",
      "  5. например: 0.0112\n",
      "  1. сука: 229.1228\n",
      "  2. дебил: 184.6722\n",
      "  3. хохлов: 154.2461\n",
      "  4. терпи: 148.3035\n",
      "  5. хохол: 144.2625\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    top_features = get_top_features(model, feature_names, n=5)\n",
    "    for i, (feature, importance) in enumerate(top_features, 1):\n",
    "        print(f\"  {i}. {feature}: {importance:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
